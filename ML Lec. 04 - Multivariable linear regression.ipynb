{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariable linear regression\n",
    "\n",
    "### Recap\n",
    "\n",
    "* Hypothesis\n",
    "$$ H(x) = Wx + b$$\n",
    "\n",
    "* Cost Function\n",
    "$$ \\text{cost}(W,b) = { 1 \\over m} \\sum_{i=1}^m (H(x^{(i)})-y^{(i)})^2 $$\n",
    "\n",
    "* Gradient descent algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Predicting exam score: regression using one input (x)\n",
    "\n",
    "| x (Hours)  | y (score) |\n",
    "|    :---:   |   :---:   |\n",
    "|    10      |     90    |\n",
    "|     9      |     80    |\n",
    "|     3      |     50    |\n",
    "|     2      |     60    |\n",
    "|     11     |     40    |\n",
    "\n",
    "### Predicting exam score: regression using three inputs (x1, x2, x3)\n",
    "\n",
    "| x1 (quiz 1) | x2 (quiz 2)| x3 (midterm 1)  | Y (final) |\n",
    "|    :---:   |   :---:   |    :---:   |   :---:   |\n",
    "|    73      |     80    | 75 | 152 |\n",
    "|    93      |     88    | 93  | 185  |\n",
    "|    89      |     91    |  90  | 180  |\n",
    "|    96      |     98    |   100 |  196  |\n",
    "|    73     |     66    |   70   | 142   |\n",
    "\n",
    "\n",
    "####  Hypothesis\n",
    "\n",
    "$$ H(x) = Wx + b$$\n",
    " \n",
    "$$ H(x_1,x_2, x_3) = w_1x_1 + w_2x_2 + w_3x_3 + b$$\n",
    "\n",
    "#### Cost function\n",
    "\n",
    "$$ \\text{cost}(W,b) = { 1 \\over m} \\sum_{i=1}^m (H(x_1^{(i)}, x_2^{(i)},x_3^{(i)})-y^{(i)})^2 $$\n",
    "\n",
    "####  Multi-variable\n",
    " \n",
    "$$ H(x_1,x_2, x_3) = w_1x_1 + w_2x_2 + \\cdots + w_nx_n + b$$\n",
    "\n",
    "#### Multi-variable Hypothesis using Matrix\n",
    "\n",
    "$$  w_1x_1 + w_2x_2 + \\cdots + w_nx_n  $$\n",
    "\n",
    "$$ [ x_1  x_2  x_3 ] \\cdot \\begin{bmatrix} w_1 \\\\ w_2 \\\\ w_3 \\end{bmatrix} = x_1w_1 + x_2w_2 + x_3w_3 $$\n",
    "\n",
    "$$ H(X) = XW $$\n",
    "\n",
    "\n",
    "For many instances ...\n",
    "$$ \\begin{bmatrix} \n",
    "x_{11}  & x_{12} & x_{13} \\\\\n",
    "x_{21}  & x_{22} & x_{33} \\\\\n",
    "x_{31}  & x_{32} & x_{33} \\\\\n",
    "x_{41}  & x_{42} & x_{43} \\\\\n",
    "x_{51}  & x_{52} & x_{53}\n",
    "\\end{bmatrix} \\cdot \n",
    "\\begin{bmatrix} w_1 \\\\ w_2 \\\\ w_3  \\end{bmatrix}\n",
    "= \n",
    " \\begin{bmatrix} \n",
    " x_{11}w_1 + x_{12}w_2 + x_{13}w_3 \\\\\n",
    " x_{21}w_1 + x_{22}w_2 + x_{33}w_3 \\\\\n",
    " x_{31}w_1 + x_{32}w_2 + x_{33}w_3 \\\\\n",
    " x_{41}w_1 + x_{42}w_2 + x_{43}w_3 \\\\\n",
    " x_{51}w_1 + x_{52}w_2 + x_{53}w_3 \n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "  \n",
    " [n x 3] * [3 x 1] = [n x 1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XW vs XW\n",
    "\n",
    "* Lecture(i.e. theory)\n",
    "$$ H(x) = Wx + b $$\n",
    "* Implementation (i.e. Tensorflow)\n",
    "$$ H(X) = X W $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 4-1\n",
    "\n",
    "| $x_1$ |  $x_2$|  $x_3$  | Y  |\n",
    "|    :---:   |   :---:   |    :---:   |   :---:   |\n",
    "|    73      |     80    | 75 | 152 |\n",
    "|    93      |     88    | 93  | 185  |\n",
    "|    89      |     91    |  90  | 180  |\n",
    "|    96      |     98    |   100 |  196  |\n",
    "|    73     |     66    |   70   | 142   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  197999.1 \n",
      "Prediction: \n",
      " [-251.6882  -283.95578 -289.39877 -316.06317 -210.94164]\n",
      "400 Cost:  32.75611 \n",
      "Prediction: \n",
      " [144.0221  189.90645 178.41617 193.28487 150.1351 ]\n",
      "800 Cost:  26.472574 \n",
      "Prediction: \n",
      " [144.85384 189.33496 178.66939 193.48056 149.37463]\n",
      "1200 Cost:  21.412365 \n",
      "Prediction: \n",
      " [145.59961 188.82245 178.8963  193.65706 148.69165]\n",
      "1600 Cost:  17.33698 \n",
      "Prediction: \n",
      " [146.26826 188.36285 179.09961 193.81636 148.07819]\n",
      "2000 Cost:  14.054525 \n",
      "Prediction: \n",
      " [146.86769 187.95065 179.2817  193.96017 147.5271 ]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], \n",
    "                                  feed_dict={x1: x1_data, x2:x2_data, x3: x3_data, Y: y_data})\n",
    "    if step % 400 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction: \\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplify the code using Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  133870.17 \n",
      "Prediction: \n",
      " [[-168.18774]\n",
      " [-208.99846]\n",
      " [-202.53593]\n",
      " [-220.76196]\n",
      " [-160.60805]]\n",
      "400 Cost:  10.768486 \n",
      "Prediction: \n",
      " [[155.9149 ]\n",
      " [181.54868]\n",
      " [181.75726]\n",
      " [197.77518]\n",
      " [137.48723]]\n",
      "800 Cost:  8.720679 \n",
      "Prediction: \n",
      " [[155.44022]\n",
      " [181.87485]\n",
      " [181.61276]\n",
      " [197.66328]\n",
      " [137.9215 ]]\n",
      "1200 Cost:  7.0715227 \n",
      "Prediction: \n",
      " [[155.0146 ]\n",
      " [182.16737]\n",
      " [181.48328]\n",
      " [197.56235]\n",
      " [138.31151]]\n",
      "1600 Cost:  5.74327 \n",
      "Prediction: \n",
      " [[154.63301]\n",
      " [182.4297 ]\n",
      " [181.3673 ]\n",
      " [197.47124]\n",
      " [138.66187]]\n",
      "2000 Cost:  4.673442 \n",
      "Prediction: \n",
      " [[154.29092]\n",
      " [182.66492]\n",
      " [181.26337]\n",
      " [197.38892]\n",
      " [138.97658]]\n"
     ]
    }
   ],
   "source": [
    "x_data = [[73., 80., 75.], \n",
    "          [93., 88., 93.],\n",
    "          [89., 91., 90.],\n",
    "          [96., 98., 100.],\n",
    "          [73., 66., 70.]]\n",
    "y_data = [[152.], [185.], [180.], [196.], [142.]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], \n",
    "                                  feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 400 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction: \\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab. 4-2 : Loading data from file\n",
    "\n",
    "text file as ./data/data-01-test-score.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 46, 55, 101)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXAM1,EXAM2,EXAM3,FINAL\n",
    "73,80,75,152\n",
    "93,88,93,185\n",
    "89,91,90,180\n",
    "96,98,100,196\n",
    "73,66,70,142\n",
    "53,46,55,101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3) [[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]\n",
      " [ 53.  46.  55.]] 6\n",
      "(6, 1) [[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]\n",
      " [101.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt('data/data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:,0:-1]\n",
    "y_data = xy[:,[-1]]\n",
    "\n",
    "print(x_data.shape, x_data, len(x_data))\n",
    "print(y_data.shape, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  7713.289 \n",
      "Prediction: \n",
      " [[72.59785 ]\n",
      " [82.759285]\n",
      " [83.746605]\n",
      " [92.50187 ]\n",
      " [60.949173]\n",
      " [46.44678 ]]\n",
      "400 Cost:  8.877568 \n",
      "Prediction: \n",
      " [[154.61263 ]\n",
      " [181.99835 ]\n",
      " [181.18567 ]\n",
      " [198.6222  ]\n",
      " [136.799   ]\n",
      " [102.448296]]\n",
      "800 Cost:  7.9793277 \n",
      "Prediction: \n",
      " [[154.29158]\n",
      " [182.16882]\n",
      " [181.06693]\n",
      " [198.4927 ]\n",
      " [137.06749]\n",
      " [102.71099]]\n",
      "1200 Cost:  7.25989 \n",
      "Prediction: \n",
      " [[154.01105]\n",
      " [182.31921]\n",
      " [180.96436]\n",
      " [198.37482]\n",
      " [137.3085 ]\n",
      " [102.93611]]\n",
      "1600 Cost:  6.6783633 \n",
      "Prediction: \n",
      " [[153.76598 ]\n",
      " [182.45206 ]\n",
      " [180.87593 ]\n",
      " [198.2672  ]\n",
      " [137.5254  ]\n",
      " [103.128395]]\n",
      "2000 Cost:  6.203535 \n",
      "Prediction: \n",
      " [[153.55196 ]\n",
      " [182.56949 ]\n",
      " [180.79988 ]\n",
      " [198.16861 ]\n",
      " [137.72107 ]\n",
      " [103.292015]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], \n",
    "                                  feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 400 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction: \\n\", hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score will be  [[179.4285]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(\"Your score will be \", sess.run(hypothesis, feed_dict={X:[[100, 70, 101]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score will be  [[183.47055]\n",
      " [176.3312 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Your score will be \", sess.run(hypothesis, \n",
    "                                      feed_dict={X:[[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queue Runners\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/223B9B4958F7733C01\">\n",
    "\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/210E514958F7733B3C\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.train.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    ['data/data-01-test-score.csv'], shuffle=False, name='filename_queue')\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "record_defaults = [[0.], [0.], [0.], [0.]]\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
    "   \n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Start populating the filename queue.\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "for step in range(2001):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], \n",
    "                                  feed_dict={X: x_batch, Y: y_batch})\n",
    "    if step % 400 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction: \\n\", hy_val)\n",
    "    \n",
    "coord.request_stop()\n",
    "coord.join(thresds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "filename_queue = tf.train.string_input_producer(\\\n",
    "        ['data/data-01-test-score.csv'], shuffle=False, name='filename_queue')\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# Default values, in case of empty columns. Also specifies the type of the decoded result.\n",
    "record_defaults = [[0.], [0.],[0.],[0.]]\n",
    "xy = tf.decode_csv(value, record_defaults = record_defaults)\n",
    "\n",
    "#collect batches of csv in\n",
    "train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
    "\n",
    "#placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "#Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a sesseion.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Start populating the filename queue.\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "for step in range(2001):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train],\n",
    "        feed_dict={X: x_batch, Y: y_batch})\n",
    "    if step % 10 == 0:\n",
    "        print(step, \"Cost: \", cost_val,\n",
    "                     \"\\nPrediction:\\n\", hy_val)\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
